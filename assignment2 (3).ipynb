{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87148ce1-377c-43db-a028-29b3ebb9808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 1\n",
    "    \n",
    "Feature selection reduces the computation cost and improves the performance of the models. \n",
    "The number of input variables has to be reduced to reduce the complexity of the system.\n",
    "Chi-square metric is used along with classification strategies for optimal results.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3afdf-63c8-4bff-8c32-2ccd91c2a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 2\n",
    "   \n",
    "Several evaluation metrics are commonly used to assess the performance of anomaly detection algorithms. Some of the key metrics include:\n",
    "\n",
    "1. **Precision, Recall, and F1-Score**: These metrics are commonly used for binary classification tasks, where anomalies are treated as the positive class and normal instances as the negative class. Precision measures the proportion of correctly identified anomalies among all instances flagged as anomalies, recall measures the proportion of correctly identified anomalies among all true anomalies, and the F1-score is the harmonic mean of precision and recall.\n",
    "\n",
    "   - Precision = \\(\\frac{\\text{True Positives}}{\\text{True Positives + False Positives}}\\)\n",
    "   - Recall = \\(\\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}}\\)\n",
    "   - F1-Score = \\(2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision + Recall}}\\)\n",
    "\n",
    "2. **Receiver Operating Characteristic (ROC) Curve and Area Under the Curve (AUC)**: ROC curves plot the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. AUC measures the area under the ROC curve, indicating the classifier's ability to distinguish between anomalies and normal instances. A higher AUC value indicates better performance.\n",
    "\n",
    "3. **Precision-Recall (PR) Curve and Area Under the Curve (AUC-PR)**: PR curves plot precision against recall at various threshold settings. AUC-PR measures the area under the PR curve, providing a summary of the trade-off between precision and recall. A higher AUC-PR value indicates better performance.\n",
    "\n",
    "4. **Confusion Matrix**: The confusion matrix provides a tabular summary of the number of true positives, false positives, true negatives, and false negatives. It is useful for understanding the performance of the algorithm across different classes and calculating metrics such as precision and recall.\n",
    "\n",
    "5. **Anomaly Detection Rate (ADR)**: ADR measures the percentage of anomalies correctly identified by the algorithm. It is calculated as the ratio of true positives to the total number of anomalies in the dataset.\n",
    "\n",
    "6. **False Positive Rate (FPR)**: FPR measures the proportion of normal instances incorrectly flagged as anomalies by the algorithm. It is calculated as the ratio of false positives to the total number of true negatives and false positives.\n",
    "\n",
    "7. **Mean Average Precision (mAP)**: mAP is the average precision calculated across multiple threshold settings. It provides a single scalar value summarizing the precision-recall curve.\n",
    "\n",
    "These evaluation metrics provide insights into various aspects of the anomaly detection algorithm's performance, including its ability to detect anomalies accurately, its robustness to false positives, and its overall discriminative power. Choosing the appropriate metrics depends on the specific characteristics of the dataset and the desired trade-offs between different performance criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb504f1-b0f8-4fb7-ace5-fe3472c649d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 3\n",
    "    \n",
    "DBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. \n",
    "It is a popular unsupervised learning method used for model construction and machine learning algorithms. \n",
    "It is a clustering method utilized for separating high-density clusters from low-density clusters.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71bcc3-3dbb-4891-987b-01b1f9e9c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 4\n",
    "    \n",
    "DBSCAN requires only two parameters: epsilon and minPoints. Epsilon is the radius of the circle to be created \n",
    "around each data point to check the density and minPoints is the minimum number of data points required inside\n",
    "that circle for that data point to be classified as a Core point.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f038bbf-72a0-4a74-80f5-b2160309290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 5\n",
    "    \n",
    "In DBSCAN (Density-Based Spatial Clustering of Applications with Noise), points in a dataset are classified into three categories: core points, border points, and noise points. These classifications are based on the density of points in the neighborhood of each data point. Here's how they are defined:\n",
    "\n",
    "1. **Core Points**: A core point is a data point that has at least a specified number of neighboring points (MinPts) within a specified radius (eps). In other words, a core point has a dense neighborhood. Core points are central to clusters and often form the backbone of clusters.\n",
    "\n",
    "2. **Border Points**: A border point is a data point that is within the neighborhood of a core point but does not have enough neighboring points to be considered a core point itself. Border points are on the edge of clusters and may be part of multiple clusters.\n",
    "\n",
    "3. **Noise Points**: A noise point (also called an outlier) is a data point that is neither a core point nor a border point. These points are often isolated and do not belong to any cluster.\n",
    "\n",
    "Now, relating these concepts to anomaly detection:\n",
    "\n",
    "- **Core Points**: Core points are unlikely to be anomalies because they are surrounded by a dense neighborhood of similar points, indicating that they are part of a cluster. Anomalies are typically isolated instances, so core points are not considered anomalies.\n",
    "\n",
    "- **Border Points**: Border points can be considered ambiguous in terms of anomaly detection. They are on the edge of clusters and may have some similarity to the points in the cluster, but they are not as central as core points. Depending on the application and the specific context, border points could be considered anomalies if they deviate significantly from the cluster's characteristics.\n",
    "\n",
    "- **Noise Points**: Noise points are often treated as anomalies in DBSCAN-based anomaly detection. Since they do not belong to any cluster and are often isolated, they are likely to represent unusual or outlying behavior in the dataset.\n",
    "\n",
    "Overall, DBSCAN can be used for anomaly detection by considering noise points as anomalies or by analyzing the characteristics of border points to determine if they represent anomalous behavior. The choice depends on the specific requirements of the anomaly detection task and the underlying assumptions about the data.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4804fa-1c4b-4fe1-b5a6-cc960de78d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 6\n",
    "    \n",
    "DBSCAN requires only two parameters: epsilon and minPoints. \n",
    "Epsilon is the radius of the circle to be created around each data point to check the density and minPoints\n",
    "is the minimum number of data points required inside that circle for that data point to be classified as a Core \n",
    "point.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b3484-7e43-42c6-8cb3-568c269b3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 7\n",
    "    \n",
    "Make a large circle containing a smaller circle in 2d.\n",
    "A simple toy dataset to visualize clustering and classification algorithms.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359769a-59d9-477d-a19b-7d90baf25a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 8\n",
    "    \n",
    "a global outlier, outlier detection considers all data points, \n",
    "and the data point pt is considered an outlier if it is far away from all other data points    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343651d1-13aa-46c9-98e1-dedbb195435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 9\n",
    "   \n",
    "By comparing the density of the data point and density of all the data points in the neighborhood,\n",
    "whether the density of the data point is lower than the density of the neighborhood can be determined. \n",
    "This scenario indicates the presence of an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78dfef-242a-4e93-a9dd-96a0306f8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 10\n",
    "   \n",
    "At its core, the Isolation Forest algorithm, it banks on the fundamental concept that anomalies, \n",
    "they deviate significantly, thereby making them easier to identify. Isolation Forests excel at anomaly detection \n",
    "by leveraging a unique approach: isolating anomalies instead of profiling normal data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fcc090-367f-4022-8133-edac6531b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 11\n",
    "   \n",
    "Local outlier detection methods focus on identifying outliers based on their local neighborhoods, while global outlier detection methods consider the entire dataset when identifying outliers. The choice between these two approaches depends on the characteristics of the data and the specific requirements of the application. Here are some real-world applications where each approach may be more appropriate:\n",
    "\n",
    "Local Outlier Detection:\n",
    "1. **Anomaly Detection in Time-Series Data**: In time-series data, anomalies may occur locally within certain time windows rather than affecting the entire dataset. Local outlier detection methods are suitable for identifying such anomalies by considering the local neighborhoods of data points within the time series.\n",
    "\n",
    "2. **Network Intrusion Detection**: In cybersecurity applications, network intrusions often manifest as localized anomalous behavior within certain network segments or protocols. Local outlier detection methods can effectively identify these localized anomalies without being influenced by normal behavior in other parts of the network.\n",
    "\n",
    "3. **Spatial Anomaly Detection**: In spatial datasets such as geographic data or sensor networks, anomalies may occur in specific geographic regions or sensor clusters. Local outlier detection methods can identify anomalies within these local regions by considering the spatial proximity of data points.\n",
    "\n",
    "4. **Anomaly Detection in Image Processing**: In image processing applications, anomalies may appear as localized irregularities or outliers within certain regions of an image. Local outlier detection methods can be used to detect these anomalies by analyzing the local characteristics of image patches or regions.\n",
    "\n",
    "Global Outlier Detection:\n",
    "1. **Financial Fraud Detection**: In financial transactions, anomalies such as fraudulent activities may affect the entire dataset rather than being localized to specific transactions or accounts. Global outlier detection methods are suitable for identifying these widespread anomalies by considering the overall distribution of financial transactions.\n",
    "\n",
    "2. **Healthcare Anomaly Detection**: In healthcare datasets, anomalies such as rare diseases or medical conditions may affect a small proportion of patients across the entire population. Global outlier detection methods can effectively identify these rare anomalies by analyzing the overall distribution of patient data.\n",
    "\n",
    "3. **Quality Control in Manufacturing**: In manufacturing processes, anomalies such as defective products or equipment failures may affect the entire production line or manufacturing facility. Global outlier detection methods can be used to identify these widespread anomalies by analyzing the overall distribution of production metrics or sensor readings.\n",
    "\n",
    "4. **Credit Card Fraud Detection**: In credit card transactions, anomalies such as fraudulent activities may involve coordinated attacks across multiple transactions or accounts. Global outlier detection methods are suitable for identifying these coordinated anomalies by analyzing the overall distribution of transaction patterns and behaviors.\n",
    "\n",
    "In summary, the choice between local and global outlier detection methods depends on the nature of the data and the specific characteristics of the anomalies that need to be detected. Local outlier detection methods are more appropriate for identifying localized anomalies within specific neighborhoods or regions, while global outlier detection methods are suitable for identifying widespread anomalies that affect the entire dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
